import pandas as pd
import zipfile
import requests
import io
import nltk
import streamlit as st
import numpy as np
import spacy
from textblob import TextBlob
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report

# Baixar recursos necessÃ¡rios do NLTK
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')
nltk.download('stopwords')

import en_core_web_md
nlp = en_core_web_md.load()




# ----- FunÃ§Ãµes de Processamento e Modelagem -----
@st.cache_data
def carregar_dados():
    """
    Baixa o dataset de tweets sobre companhias aÃ©reas.
    O dataset Ã© extraÃ­do de um arquivo zip e carregado em um DataFrame.
    """
    url = 'https://github.com/alexvaroz/data_science_alem_do_basico/raw/refs/heads/master/tweets_airlines.zip'
    response = requests.get(url)
    z = zipfile.ZipFile(io.BytesIO(response.content))
    csv_filename = [name for name in z.namelist() if name.endswith('.csv')][0]
    df = pd.read_csv(z.open(csv_filename))
    return df


def analisar_sentimento_textblob(text):
    """
    Analisa o sentimento de um tweet usando o TextBlob.
    - 'positivo' se o sentimento for positivo,
    - 'negativo' se o sentimento for negativo,
    - 'neutro' se o sentimento nÃ£o for forte.
    """
    analysis = TextBlob(str(text))
    if analysis.sentiment.polarity > 0:
        return 'positive'
    elif analysis.sentiment.polarity < 0:
        return 'negative'
    else:
        return 'neutral'


def treinar_tfidf_model(df):
    """
    Treina um modelo de aprendizado de mÃ¡quina usando TF-IDF e RegressÃ£o LogÃ­stica.
    O TF-IDF transforma o texto em nÃºmeros para que o modelo possa entender.
    A RegressÃ£o LogÃ­stica Ã© usada para fazer a previsÃ£o do sentimento do tweet.
    """
    X_train, X_test, y_train, y_test = train_test_split(df['text'], df['airline_sentiment'], test_size=0.2,
                                                        random_state=42)
    vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)
    X_train_vec = vectorizer.fit_transform(X_train)
    X_test_vec = vectorizer.transform(X_test)
    model = LogisticRegression(max_iter=1000)
    model.fit(X_train_vec, y_train)
    y_pred = model.predict(X_test_vec)
    return y_test, y_pred, accuracy_score(y_test, y_pred), classification_report(y_test, y_pred)


def treinar_spacy_model(df):
    """
    Treina um modelo de aprendizado de mÃ¡quina usando embeddings do SpaCy e RegressÃ£o LogÃ­stica.
    O SpaCy transforma o texto em vetores numÃ©ricos (embeddings) e a RegressÃ£o LogÃ­stica Ã© usada para prever o sentimento.
    """
    df = df.copy()

    def get_vector(text):
        doc = nlp(str(text))
        return doc.vector if doc.has_vector else np.zeros(nlp.vocab.vectors_length)

    df['spacy_vector'] = df['text'].apply(get_vector)

    X = np.vstack(df['spacy_vector'].values)
    y = df['airline_sentiment']

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    model = LogisticRegression(max_iter=1000)
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    return y_test, y_pred, accuracy_score(y_test, y_pred), classification_report(y_test, y_pred)


# ----- Interface do Streamlit -----
st.set_page_config(page_title="AnÃ¡lise de Sentimentos Comparativa", layout="wide")
st.title("âœˆï¸ AnÃ¡lise de Sentimentos com ComparaÃ§Ã£o de Modelos")


# Carregar os dados
df = carregar_dados()
st.write("ðŸ” Amostra dos dados:")
st.dataframe(df[['text', 'airline_sentiment']].sample(5))

# ExplicaÃ§Ã£o geral das mÃ©tricas
with st.expander("â„¹ï¸MÃ©tricas de AvaliaÃ§Ã£o?"):
    st.markdown("""
    **Precision (PrecisÃ£o)**: Mede a acurÃ¡cia das previsÃµes feitas como **positivas**.
    - Quanto o modelo estÃ¡ correto quando prevÃª algo como positivo.

    **Recall (RevocaÃ§Ã£o ou Sensibilidade)**: Mede a capacidade do modelo de identificar **todos** os positivos reais.
    - Quanto o modelo consegue identificar todos os casos positivos de fato.

    **F1-Score**: Combina a precisÃ£o e o recall em uma Ãºnica mÃ©trica, equilibrando ambos.
    - Uma mÃ©dia ponderada entre a precisÃ£o e o recall. Uma boa mÃ©trica quando temos desequilÃ­brio entre as classes.

    **AcurÃ¡cia**: Percentual de acertos totais (todas as previsÃµes corretas divididas pelo total de previsÃµes).
    - A proporÃ§Ã£o de previsÃµes corretas feitas pelo modelo.

    **Macro avg**: MÃ©dia das mÃ©tricas (precisÃ£o, recall e F1) calculadas para cada classe, sem levar em consideraÃ§Ã£o o nÃºmero de exemplos em cada classe.

    **Weighted avg**: MÃ©dia ponderada das mÃ©tricas, considerando a proporÃ§Ã£o de cada classe no total de dados.

    Essas mÃ©tricas ajudam a entender **onde o modelo acerta mais** e **onde pode melhorar**. Elas sÃ£o importantes para avaliar a qualidade da previsÃ£o do modelo, especialmente quando as classes podem estar desequilibradas.
    """)

# --- TextBlob ---
st.header("ðŸ”  TextBlob")

# ExplicaÃ§Ã£o sobre o mÃ©todo TextBlob
with st.expander("â„¹ï¸ O que Ã© o TextBlob?"):
    st.markdown("""
    O **TextBlob** Ã© uma biblioteca simples e poderosa para anÃ¡lise de sentimentos. Ela atribui um valor de **polaridade** a cada texto. 
    - **Polaridade positiva**: Sentimentos positivos.
    - **Polaridade negativa**: Sentimentos negativos.
    - **Polaridade neutra**: Sentimentos neutros.

    Ele calcula a polaridade do texto e, com isso, conseguimos identificar rapidamente se o sentimento Ã© positivo, negativo ou neutro.
    """)

df['pred_textblob'] = df['text'].apply(analisar_sentimento_textblob)
acc_blob = accuracy_score(df['airline_sentiment'], df['pred_textblob'])
st.metric("ðŸŽ¯ AcurÃ¡cia (TextBlob)", f"{acc_blob * 100:.2f}%")

with st.expander("ðŸ“‹ RelatÃ³rio TextBlob"):
    st.text(classification_report(df['airline_sentiment'], df['pred_textblob']))

# --- TF-IDF + Logistic Regression ---
st.header("ðŸ“Š TF-IDF + Logistic Regression")

# ExplicaÃ§Ã£o sobre o mÃ©todo TF-IDF + Logistic Regression
with st.expander("â„¹ï¸ O que Ã© TF-IDF + Logistic Regression?"):
    st.markdown("""
    O **TF-IDF (Term Frequency-Inverse Document Frequency)** Ã© uma tÃ©cnica que transforma o texto em nÃºmeros, dando mais peso a palavras importantes.
    Em seguida, o modelo de **RegressÃ£o LogÃ­stica** usa esses nÃºmeros para fazer previsÃµes. Ele Ã© um classificador, ou seja, ele tenta adivinhar a categoria (positivo/negativo) de um tweet com base nas palavras.

    - **TF-IDF**: Transforma o texto em nÃºmeros.
    - **RegressÃ£o LogÃ­stica**: Classifica o sentimento com base nos nÃºmeros gerados pelo TF-IDF.
    """)

y_test_tfidf, y_pred_tfidf, acc_tfidf, report_tfidf = treinar_tfidf_model(df)
st.metric("ðŸŽ¯ AcurÃ¡cia (TF-IDF)", f"{acc_tfidf * 100:.2f}%")
with st.expander("ðŸ“‹ RelatÃ³rio TF-IDF"):
    st.text(report_tfidf)

# --- SpaCy Embeddings + Logistic Regression ---
st.header("ðŸ§  SpaCy Embeddings + Logistic Regression")

# ExplicaÃ§Ã£o sobre o mÃ©todo SpaCy + Logistic Regression
with st.expander("â„¹ï¸ O que Ã© SpaCy + Logistic Regression?"):
    st.markdown("""
    O **SpaCy** Ã© uma biblioteca que cria representaÃ§Ãµes vetoriais chamadas **embeddings**. Cada palavra Ã© transformada em um vetor de nÃºmeros que captura o significado semÃ¢ntico da palavra.
    Com isso, a **RegressÃ£o LogÃ­stica** usa esses vetores para classificar o sentimento de cada tweet.

    - **Embeddings do SpaCy**: Captura o significado semÃ¢ntico das palavras.
    - **RegressÃ£o LogÃ­stica**: Classifica o sentimento com base nos embeddings.
    """)

y_test_spacy, y_pred_spacy, acc_spacy, report_spacy = treinar_spacy_model(df)
st.metric("ðŸŽ¯ AcurÃ¡cia (SpaCy)", f"{acc_spacy * 100:.2f}%")
with st.expander("ðŸ“‹ RelatÃ³rio SpaCy"):
    st.text(report_spacy)

# ComparaÃ§Ã£o visual (grÃ¡fico de linha)
st.header("ðŸ“ˆ ComparaÃ§Ã£o de AcurÃ¡cia entre os modelos")

# GrÃ¡fico de linha comparando os trÃªs modelos
acuracia_df = pd.DataFrame({
    "Modelos": ["TextBlob", "TF-IDF + LR", "SpaCy + LR"],
    "AcurÃ¡cia": [acc_blob, acc_tfidf, acc_spacy]
})

st.line_chart(acuracia_df.set_index("Modelos"))

# --- ConclusÃ£o ---
st.header("ðŸ”š ConclusÃ£o")

st.markdown("""
Com base nos resultados obtidos, podemos comparar o desempenho de cada modelo utilizado para anÃ¡lise de sentimentos:

1. **TextBlob**:
   - AcurÃ¡cia: **46.44%**
   - O modelo **TextBlob** obteve uma acurÃ¡cia relativamente baixa, com desempenho fraco, especialmente em identificar sentimentos **negativos** e **positivos**. Isso ocorre porque o TextBlob Ã© uma abordagem mais simples que utiliza anÃ¡lise de polaridade, mas que nÃ£o leva em conta o contexto mais profundo das palavras.

2. **TF-IDF + Logistic Regression**:
   - AcurÃ¡cia: **79.58%**
   - O modelo **TF-IDF + RegressÃ£o LogÃ­stica** obteve a melhor acurÃ¡cia entre os trÃªs. Ele usou a tÃ©cnica de transformaÃ§Ã£o **TF-IDF**, que cria representaÃ§Ãµes numÃ©ricas das palavras, permitindo que o modelo compreenda melhor o contexto semÃ¢ntico do texto. O classificador de **RegressÃ£o LogÃ­stica** fez um trabalho eficaz de identificar os sentimentos presentes.

3. **SpaCy Embeddings + Logistic Regression**:
   - AcurÃ¡cia: **74.59%**
   - O modelo **SpaCy + RegressÃ£o LogÃ­stica** obteve uma boa acurÃ¡cia, mas ficou atrÃ¡s do TF-IDF. Embora o SpaCy utilize **embeddings**, que capturam o significado semÃ¢ntico das palavras de forma mais profunda, o modelo nÃ£o teve um desempenho tÃ£o superior quanto o TF-IDF, possivelmente por causa de como o SpaCy lida com as representaÃ§Ãµes vetoriais.

### ConclusÃ£o Final:
**TF-IDF + RegressÃ£o LogÃ­stica** foi o modelo que apresentou o melhor desempenho, com a maior acurÃ¡cia de **79.58%**. Esse modelo Ã© eficaz em transformar o texto em uma representaÃ§Ã£o numÃ©rica que captura palavras relevantes para a tarefa de anÃ¡lise de sentimentos. Apesar de **SpaCy** fornecer uma representaÃ§Ã£o semÃ¢ntica mais profunda das palavras, o TF-IDF mostrou ser mais eficiente para esta tarefa especÃ­fica.
""")
